version: 2.1

parameters:
  embedding_model:
    type: string
    default: "BAAI/bge-base-en-v1.5"
    description: "Embedding model name for the RAG pipeline."
  llm_model:
    type: string
    default: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
    description: "LLM model name for the RAG pipeline."
  evaluator_llm_model:
    type: string
    default: "Qwen/Qwen2.5-7B-Instruct-Turbo"
    description: "LLM model name used by RAGAS for evaluation metrics."
  doc_sample_size:
    type: integer
    default: 100
    description: "Number of documents to sample from Dolly dataset for vector store."
  query_sample_size:
    type: integer
    default: 5
    description: "Number of queries to sample from Dolly dataset for evaluation."

jobs:
  rag_evaluation:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: pip install -r requirements.txt
      - run:
          name: Run RAGAS Evaluation
          # Passes parameters to Python process execution environment. Overrides default values.
          command: |
            EMBEDDING_MODEL_NAME="<< pipeline.parameters.embedding_model >>" \
            LLM_MODEL_NAME="<< pipeline.parameters.llm_model >>" \
            EVALUATOR_LLM_NAME="<< pipeline.parameters.evaluator_llm_model >>" \
            DOCUMENTS_SAMPLE_SIZE="<< pipeline.parameters.doc_sample_size >>" \
            QUERY_SAMPLE_SIZE="<< pipeline.parameters.query_sample_size >>" \
            python3 main.py
      - store_artifacts:
          path: ragas_results.csv
          destination: ragas_evaluation_results
      - store_artifacts:
          path: rag_results.json
          destination: rag_raw_results

workflows:
  pipeline:
    jobs:
      - rag_evaluation